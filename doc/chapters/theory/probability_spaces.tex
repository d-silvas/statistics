% TODO: sigma-algebras...

\subsection{Definition and basic properties}

\begin{definition}
	\textbf{Random Experiment:} an experiment whose outcomes are determined only by chance factors.
\end{definition}

\begin{definition}
	The description of a random experiment starts by identifying the set of all possible  outcomes of the experiment, which we call \textbf{sample space}, and we designate by $\O$.
	\begin{itemize}
		\item When $\O$ is finite or countable (\textit{numerable}), we say that the probability model is \textbf{discrete}.
		\item When $\O$ is uncountable, we say that the probability model is \textbf{continuous}.
	\end{itemize}
\end{definition}

\begin{definition}
	Let $\O$ be a set and $\F$ a $\sigma$-algebra on $\O$. We say that $(\O, \F)$ is a \textbf{measurable space}. Any subset belonging to $\F$ is called an \textbf{event}.
	\begin{itemize}
		\item When $\O$ is finite or countable, we will usually consider $\F = \mathcal{P}(\O)$.
		\item When $\O$ is uncountable, with $\O \subseteq \R^k$, we will usually consider $\F = \mathbb{B}_{\O}^k$.
	\end{itemize}
\end{definition}

\begin{definition}
	Given a measurable space $(\O, \F)$, a \textbf{probability}, or \textbf{probability measure}, is a function $\P: \F \rightarrow \R$ such that:
	\begin{enumerate}[i)]
		\item $\P(A) \geq 0$ for every $A \in \F$.
		\item For every countable collection of events $\{A_n\} \subset \F$, which are pairwise disjoint, we have that:
		\[
			\P \left(\cup_n A_n\right) = \sum_n \P(A_n)
		\]
		\item $\P(\O) = 1$
	\end{enumerate}
	If $\P$ is a probability in $(\O, \F)$, we call the triad $(\O, \F, \P)$ a \textbf{probability space}. For every event $A \in \F$, we call $\P(A)$ the \textbf{probability of $A$}.
\end{definition}

\begin{definition}
	\textbf{Sample Space:} the set of all possible outcomes of a random experiment.
\end{definition}

\begin{definition}
	\textbf{Event:} the collection of none, one, or more than one outcomes from a sample space.
\end{definition}

\begin{definition}
	\textbf{Random Variable}: a variable whose numerical values are determined by chance factors. It is a function from the sample space to a set of real numbers.
\end{definition}

Given a sample space $\Omega = \{ \omega_1, \ldots, \omega_n \}$ with probability function $P$ and a random variable $X$ with range $\mathbb{X} = \{ x_1, \ldots x_m \}$, we can define a probability function $P_X$ on $\mathbb{X}$ in the following way: We will observe $X = x_i$ if and only if the outcome of the random experiment is an $\omega_i \in \Omega$ such that $X(\omega_j) = x_i$. Thus,
\[
	P_X(X = x_i) = P(\{ \omega_j \in \Omega \mid X(\omega_j) = x_i \})
\]
The function $P_X$ is an \textit{induced} probability function on $\mathbb{X}$, defined in terms of the orginal function $P$. We will write $P(X = x_i)$ rather than $P_X(X = x_i)$.
\begin{definition}
	\textbf{Discrete Random Variable:} if the set of all possible values of a random variable $X$ is countable, then $X$ is called a \textit{discrete random variable}.
\end{definition}

\begin{definition}
	\textbf{Probability Mass Function (pmf):} let $R$ be the set of all possible values of a discrete random variable $X$, and $f(k) = P(X = k)$ for each $k$ in $R$. Then $f(k)$ is called the \textit{probability mass function} of $X$.
\end{definition}

\begin{definition}
	\textbf{Continuous Random Variable:} if the set of all possible values of $X$ an interval or union of two or more nonoverlapping intervals in $\mathbb{R}$, then $X$ is called a \textit{continuous random variable}.
\end{definition}

\begin{definition}
	\textbf{Probability Density Function (pdf):} any real valued function $f(x)$ that satisfies the following requirements is called a \textit{probability density function}:
	\[
		f(x) \geq 0 \text{ for all } x, \text{ and } \int_{-\infty}^{\infty}f(x)\,dx = 1
	\]
\end{definition}

\begin{definition}
	\textbf{Cumulative Distribution function (cdf):} the \textit{cumulative distribution function} of a random variable $X$ is defined by
	\[
		F(x) = P(X \leq x)
	\]
	For a continuous random variable $X$ with the probability density function $f(x)$,
	\[
	F(x) = P(X \leq x) = \int_{-\infty}^x f(t)\,dt, \ \forall x
	\]
	For a discrete random variable $X$, the \textit{cdf} is defined by
	\[
	F(k) = P(X \leq k) = \sum_{i = -\infty}^k P(X = i)
	\]
\end{definition}
The \textit{pdf} (or \textit{pmf}) contains the same information as the \textit{cdf}.

If the distribution of a random variable $X$ depends on a parameter $\theta$, the the \textit{pdf} or \textit{pmf} of $X$ is usually expressed as $f(x \mid \theta)$, and the \textit{cdf} is written as $F(x \mid \theta)$
\begin{theorem}
	A function $F(x)$ is a cdf if and only if the following three conditions hold:
	\begin{enumerate}[\bfseries a)]
		\item $\lim_{x \rightarrow -\infty}F(x) = 0$ and $\lim_{x \rightarrow \infty}F(x) = 1$.
		\item $F(x)$ is a nondecreasing function of x.
		\item $F(x)$ is right-continuous; that is, for every number $x_0$, $\lim_{x \rightarrow x_0^{+}} F(x) = F(x_0)$
	\end{enumerate}
\end{theorem}

\begin{definition}
	\textbf{Expectation:} if $X$ is a continuous random variable with the \textit{pdf} $f(x)$, then the expectation of $g(X)$, where $g$ is a real valued function, is defined by
	\[
		E(g(X)) = \int_{-\infty}^{\infty}g(x)f(x)\,dx
	\]
	If $X$ is a discrete random variable, then
	\[
		E(g(X)) = \sum_k g(x) P(X = k)
	\]
	where the sum is over all possible values of $X$. Thus, $E(g(X))$ is the weighted average of the possible values of $g(X)$, each weighted by its probability.
\end{definition}

\begin{theorem}
	Let $X$ be a random variable and let a, b and c be constants. Then for any functions $g_1(x)$ and $g_2(x)$ whose expectations exist,
	\begin{enumerate}[\bfseries a)]
		\item $E(ag_1(X) + bg_2(X) + c) = aEg_1(X) + bEg_2(X) + c$.
		\item If $g_1(x) \geq 0 \ \forall x$, then $Eg_1(X) \geq 0$.
		\item If $g_1(x) \geq g_2(x) \ \forall x$, then $Eg_1(X) \geq Eg_2(X)$.
		\item If $a \leq g_1(x) \leq b \ \forall x$, then $a \leq Eg_1(X) \leq b$. 
	\end{enumerate}
\end{theorem}

\subsection{Measures of Central Tendency}

\begin{definition}
	\textbf{Mean:} the \textit{mean} of a random variable $X$ is usually denoted by $\mu$. For a discrete random variable $X$, it is defined by
	\[
		\mu = E(X) = \sum_{k}P(X = k)
	\]
	where the sum is over all possible values of $X$. For a continuous random variable $X$ with probability density function $f(x)$, the \textit{mean} is defined by
	\[
		\mu = E(X) = \int_{-\infty}^{\infty} xf(x) \, dx
	\]
\end{definition}

\begin{definition}
	\textbf{Median:} the \textit{median} of a random variable $X$ is the value such that 50\% of the possible values of $X$ are less than or equal to that value. For a discrete distribution, median is not well defined, and it need not be unique.
\end{definition}

\begin{definition}
	\textbf{Mode:} the most probable value of the random variable.
\end{definition}

\subsection{Moments}

\begin{definition}
	\textbf{Moments about the origin (Raw Moments)}: for each integer $n$, the $n$th \textit{moment} of $X$ (or $F(X)$), $\mu_n'$, is
	\[
		\mu_n' = EX^n
	\]
	For a continuous random variable this is:
	\[
		\mu_n' = EX^n = \int_{-\infty}^{\infty} x^n f(x) \, dx
	\]
	We can see that the mean is $\mu = \mu_1' = EX$.
\end{definition}

\begin{definition}
	\textbf{Moments about the mean (Central Moments):} for each integer $n$, the $n$th \textit{central moment} of $X$ (or $F(X)$), $\mu_n$, is
	\[
		\mu_n = E(X - \mu)^n
	\]
\end{definition}

\begin{definition}
	\textbf{Variance:} the \textit{variance} of a random variable $X$ is its second central moment:
	\[
		\sigma^2 = VarX = E(X - EX)^2
	\]
	An alternative formula for the variance is given by
	\[
		VarX = EX^2 - (EX)^2
	\]
\end{definition}

\begin{definition}
	\textbf{Standard deviation:} the \textit{standard deviation} of a random variable $X$ is the square root of $Var X$:
	\[
		\sigma = \sqrt{VarX}
	\]
\end{definition}

The variance gives a measure of the degree of spread of a distribution around its mean. Larger values mean $X$ is more variable. At the extreme, if $VarX = E(X - EX)^2 = 0$, then $X$ is equal to $EX$ with probability 1, and there is no variation in $X$.

The standard deviation has the same qualitative interpretation: small values mean $X$ is very likely to be close to $EX$, and large values mean $X$ is very variable. The standard deviation is easier to interpret in that the measurement unit on the standard deviation is the same as that for the original variable $X$.

\begin{theorem}
	If $X$ is a random variable with finite variance, then for any constants $a$ and $b$:
	\[
		Var(aX + b) = a^2 VarX
	\]
\end{theorem}

\begin{definition}
	\textbf{}
\end{definition}
\begin{definition}
	\textbf{}
\end{definition}